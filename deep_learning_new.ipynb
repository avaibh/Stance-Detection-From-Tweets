{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:06.798117Z",
     "start_time": "2018-11-28T08:31:06.354806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os, string, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Flatten, Dense, Dropout, Convolution1D, MaxPooling1D, SpatialDropout1D, Input \n",
    "from keras.layers import GlobalMaxPooling1D, concatenate, LSTM, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:07.367522Z",
     "start_time": "2018-11-28T08:31:06.942219Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:08.264105Z",
     "start_time": "2018-11-28T08:31:07.890625Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f'{PATH}/data/Airline-Sentiment-2-w-AA.csv', usecols=['text', 'airline_sentiment'], encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:09.287897Z",
     "start_time": "2018-11-28T08:31:08.901604Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", usecols=['Tweet Text', 'Medical relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:10.101936Z",
     "start_time": "2018-11-28T08:31:09.736661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2099, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical label class into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:17.653635Z",
     "start_time": "2018-11-28T08:31:17.267335Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['Medical relevance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:19.923446Z",
     "start_time": "2018-11-28T08:31:18.916685Z"
    }
   },
   "outputs": [],
   "source": [
    "tc = TextCleaner()\n",
    "df['clean_text'] = tc.transform(df['Tweet Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:23.083069Z",
     "start_time": "2018-11-28T08:31:22.684786Z"
    }
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:23.546400Z",
     "start_time": "2018-11-28T08:31:23.086072Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tokenized'] = df['clean_text'].apply(lambda row: tokenize(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:23.966721Z",
     "start_time": "2018-11-28T08:31:23.548401Z"
    }
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "stop.update(['amp', 'rt', 'cc'])\n",
    "stop = stop - set(['no', 'not'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:24.470211Z",
     "start_time": "2018-11-28T08:31:24.068924Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(row):\n",
    "    return [t for t in row if t not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:26.669254Z",
     "start_time": "2018-11-28T08:31:26.291954Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tokenized'] = df['tokenized'].apply(lambda row: remove_stopwords(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:27.867289Z",
     "start_time": "2018-11-28T08:31:27.486017Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:31.856282Z",
     "start_time": "2018-11-28T08:31:31.462001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @JarrodTheLord: Yall creating life and cloning animals but want us to believe there is no cure for Cancer or Aids... alright https://t.c‰Û¡ÌÝ_</td>\n",
       "      <td>[creating, life, cloning, animals, want, us, believe, no, cure, cancer, aids, alright]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @TommySobiesski: you could give GameStop the cure to cancer &amp;amp; they‰Û¡ÌÝå»d offer you $3.89 https://t.co/REjIez4G7D</td>\n",
       "      <td>[could, give, gamestop, cure, cancer, theyd, offer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This last year has been the hardest of my life - to all the cancer researchers, doctors, nurses and caregivers who are so selflessly dedicated to finding a cure and healing patients, you are my heroes and I am grateful for the hope and strength you continue to give me &amp;amp; my family</td>\n",
       "      <td>[last, year, hardest, life, cancer, researchers, doctors, nurses, caregivers, selflessly, dedicated, finding, cure, healing, patients, heroes, grateful, hope, strength, continue, give, family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The year is 2043. You opened your newspaper and read the headlines- - World Health Organization releases a cure for Cancer. - Global warming threat- eliminated! - Enrile celebrating his birthday. - Penguins can fly. .. and you've never been so happy.</td>\n",
       "      <td>[year, opened, newspaper, read, headlines, world, health, organization, releases, cure, cancer, global, warming, threat, eliminated, enrile, celebrating, birthday, penguins, fly, youve, never, happy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @gorskon: Here we go again. Yet another dubious cancer cure video. Watch to the end and see! https://t.co/JObs8QeYiS</td>\n",
       "      <td>[go, yet, another, dubious, cancer, cure, video, watch, end, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                     Tweet Text  \\\n",
       "0  RT @JarrodTheLord: Yall creating life and cloning animals but want us to believe there is no cure for Cancer or Aids... alright https://t.c‰Û¡ÌÝ_                                                                                                                                              \n",
       "1  RT @TommySobiesski: you could give GameStop the cure to cancer &amp; they‰Û¡ÌÝå»d offer you $3.89 https://t.co/REjIez4G7D                                                                                                                                                                      \n",
       "2  This last year has been the hardest of my life - to all the cancer researchers, doctors, nurses and caregivers who are so selflessly dedicated to finding a cure and healing patients, you are my heroes and I am grateful for the hope and strength you continue to give me &amp; my family   \n",
       "3  The year is 2043. You opened your newspaper and read the headlines- - World Health Organization releases a cure for Cancer. - Global warming threat- eliminated! - Enrile celebrating his birthday. - Penguins can fly. .. and you've never been so happy.                                     \n",
       "4  RT @gorskon: Here we go again. Yet another dubious cancer cure video. Watch to the end and see! https://t.co/JObs8QeYiS                                                                                                                                                                        \n",
       "\n",
       "                                                                                                                                                                                                 tokenized  \n",
       "0  [creating, life, cloning, animals, want, us, believe, no, cure, cancer, aids, alright]                                                                                                                   \n",
       "1  [could, give, gamestop, cure, cancer, theyd, offer]                                                                                                                                                      \n",
       "2  [last, year, hardest, life, cancer, researchers, doctors, nurses, caregivers, selflessly, dedicated, finding, cure, healing, patients, heroes, grateful, hope, strength, continue, give, family]         \n",
       "3  [year, opened, newspaper, read, headlines, world, health, organization, releases, cure, cancer, global, warming, threat, eliminated, enrile, celebrating, birthday, penguins, fly, youve, never, happy]  \n",
       "4  [go, yet, another, dubious, cancer, cure, video, watch, end, see]                                                                                                                                        "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Tweet Text', 'tokenized']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:42.839054Z",
     "start_time": "2018-11-28T08:31:42.460782Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_vocab_counter(row):\n",
    "    for word in row:\n",
    "        vocab_counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:43.957887Z",
     "start_time": "2018-11-28T08:31:43.558602Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_counter = collections.Counter()\n",
    "df['tokenized'].apply(update_vocab_counter);\n",
    "vocab = sorted(vocab_counter, key=vocab_counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:47.499170Z",
     "start_time": "2018-11-28T08:31:47.119903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8974"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the dictionary size to the top 5000 most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:50.824055Z",
     "start_time": "2018-11-28T08:31:50.441781Z"
    }
   },
   "outputs": [],
   "source": [
    "max_words = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary that map each token with their id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:31:59.347061Z",
     "start_time": "2018-11-28T08:31:58.980749Z"
    }
   },
   "outputs": [],
   "source": [
    "w2id = {w:i for i, w in enumerate(vocab[:max_words])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will replace each token out of top 5000 with 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:01.066098Z",
     "start_time": "2018-11-28T08:32:00.703839Z"
    }
   },
   "outputs": [],
   "source": [
    "w2id['unk'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform each token by their id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:02.998261Z",
     "start_time": "2018-11-28T08:32:02.626997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2id[\"full\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:07.127212Z",
     "start_time": "2018-11-28T08:32:06.726930Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_ids(row):\n",
    "    return [w2id[w] if w in w2id else w2id['unk'] for w in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:07.539541Z",
     "start_time": "2018-11-28T08:32:07.129217Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tokenized_int'] = df['tokenized'].apply(lambda x: transform_to_ids(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:10.973677Z",
     "start_time": "2018-11-28T08:32:10.579604Z"
    }
   },
   "outputs": [],
   "source": [
    "lens = df['tokenized_int'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:12.152776Z",
     "start_time": "2018-11-28T08:32:11.783516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 66, 21.681753215817057)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(lens), max(lens), np.mean(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set 20 as max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:14.587484Z",
     "start_time": "2018-11-28T08:32:14.230199Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:21.317907Z",
     "start_time": "2018-11-28T08:32:20.933733Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tokenized_int'].values, df['target'].values, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need that each document contains a fixed number of tokens (20), we fill with -1 (id that represents 'unk') every token with size < 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:25.903226Z",
     "start_time": "2018-11-28T08:32:25.521955Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(X_train, maxlen=maxlen, value=-1)\n",
    "x_test = pad_sequences(X_test, maxlen=maxlen, value=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We one-hot encode target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:48.103947Z",
     "start_time": "2018-11-28T08:32:47.714616Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(y_train)\n",
    "dummy_y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:22:39.220956Z",
     "start_time": "2018-11-28T07:22:39.003802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574, 60)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:22:40.435347Z",
     "start_time": "2018-11-28T07:22:40.236950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 60)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:22:43.407809Z",
     "start_time": "2018-11-28T07:22:43.209094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:56.101896Z",
     "start_time": "2018-11-28T08:32:55.687582Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:56.695158Z",
     "start_time": "2018-11-28T08:32:56.300843Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:32:59.153653Z",
     "start_time": "2018-11-28T08:32:58.402974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77380952, 0.79761905, 0.78571429, 0.75      , 0.72619048,\n",
       "       0.76190476, 0.8452381 , 0.75      , 0.76190476, 0.77245509])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, x_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:33:03.079714Z",
     "start_time": "2018-11-28T08:33:02.641403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:33:06.452273Z",
     "start_time": "2018-11-28T08:33:06.069988Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:33:07.688605Z",
     "start_time": "2018-11-28T08:33:07.322329Z"
    }
   },
   "outputs": [],
   "source": [
    " from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:53:12.836584Z",
     "start_time": "2018-11-28T08:53:12.422287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[309,  59],\n",
       "       [ 34,  18]], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[ true negative , false positive \n",
    " false negative , true positive ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:53:21.709410Z",
     "start_time": "2018-11-28T08:53:21.305080Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T08:53:48.216321Z",
     "start_time": "2018-11-28T08:53:47.796384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7785714285714286"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:34:09.248296Z",
     "start_time": "2018-11-28T07:34:08.514069Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:34:42.805819Z",
     "start_time": "2018-11-28T07:34:41.996757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:35:29.124889Z",
     "start_time": "2018-11-28T07:35:28.908736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:36:05.872971Z",
     "start_time": "2018-11-28T07:36:05.637804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T07:36:00.235354Z",
     "start_time": "2018-11-28T07:36:00.017219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T09:06:21.739565Z",
     "start_time": "2018-11-28T09:06:21.349861Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T09:06:50.013569Z",
     "start_time": "2018-11-28T09:06:49.216793Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 100, input_length=60))\n",
    "model.add(LSTM(60, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T09:13:12.505945Z",
     "start_time": "2018-11-28T09:13:12.087132Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_token = df['tokenized']\n",
    "# data_x = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T09:13:33.691953Z",
     "start_time": "2018-11-28T09:13:30.072119Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1343 samples, validate on 336 samples\n",
      "Epoch 1/20\n",
      "1343/1343 [==============================] - 7s 5ms/step - loss: 0.5780 - acc: 0.8109 - val_loss: 0.3891 - val_acc: 0.8661\n",
      "Epoch 2/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.4417 - acc: 0.8474 - val_loss: 0.3766 - val_acc: 0.8661\n",
      "Epoch 3/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.3442 - acc: 0.8563 - val_loss: 0.3017 - val_acc: 0.8839\n",
      "Epoch 4/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.1495 - acc: 0.9523 - val_loss: 0.3468 - val_acc: 0.8661\n",
      "Epoch 5/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0598 - acc: 0.9866 - val_loss: 0.4696 - val_acc: 0.8839\n",
      "Epoch 6/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0344 - acc: 0.9933 - val_loss: 0.4744 - val_acc: 0.8631\n",
      "Epoch 7/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0221 - acc: 0.9970 - val_loss: 0.5444 - val_acc: 0.8780\n",
      "Epoch 8/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0159 - acc: 0.9985 - val_loss: 0.6445 - val_acc: 0.8839\n",
      "Epoch 9/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0152 - acc: 0.9978 - val_loss: 0.6570 - val_acc: 0.8839\n",
      "Epoch 10/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0109 - acc: 0.9978 - val_loss: 0.6693 - val_acc: 0.8780\n",
      "Epoch 11/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0109 - acc: 0.9978 - val_loss: 0.6614 - val_acc: 0.8631\n",
      "Epoch 12/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.6391 - val_acc: 0.8542\n",
      "Epoch 13/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.6709 - val_acc: 0.8631\n",
      "Epoch 14/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0130 - acc: 0.9985 - val_loss: 0.7305 - val_acc: 0.8631\n",
      "Epoch 15/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.8271 - val_acc: 0.8690\n",
      "Epoch 16/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.8561 - val_acc: 0.8690\n",
      "Epoch 17/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0068 - acc: 0.9985 - val_loss: 0.8618 - val_acc: 0.8720\n",
      "Epoch 18/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.8631 - val_acc: 0.8661\n",
      "Epoch 19/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.8381 - val_acc: 0.8690\n",
      "Epoch 20/20\n",
      "1343/1343 [==============================] - 5s 4ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.8853 - val_acc: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6415b20550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train , y_train, validation_split=0.2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_lstm = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_lstm = np.round(pred_y_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[351,  17],\n",
       "       [ 28,  24]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_y_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928571428571429"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred_y_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
